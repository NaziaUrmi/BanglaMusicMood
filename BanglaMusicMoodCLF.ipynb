{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BanglaMusicMoodCLF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habibsifat/BanglaMusicMood/blob/master/BanglaMusicMoodCLF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdDAATbZEYyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import pickle\n",
        "import string\n",
        "import re\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnWjZ5mpEveG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Dataset\n",
        "df = pd.read_csv('/content/train_lyrics_bangla.txt')\n",
        "with open('/content/stopwords_bangla.txt', 'r') as infile:\n",
        "   stop_words = infile.read().splitlines()\n",
        "#print('stop words %s ...' %stop_words[:])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJcle-OHFCXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build Tokenizer for Bangla\n",
        "!pip install cltk\n",
        "from cltk.tokenize.sentence import TokenizeSentence\n",
        "def porter_tokenizer(text):\n",
        "    tokenizer = TokenizeSentence('bengali')\n",
        "    bengali_text_tokenize = tokenizer.tokenize(text)\n",
        "    bengali_text_tokenize\n",
        "    return bengali_text_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKrRWHGQFGSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate Token from Corpus\n",
        "import nltk\n",
        "lyrics = df.lyrics.str.cat(sep=' ')\n",
        "#function to split text into word\n",
        "tokens = porter_tokenizer(lyrics)\n",
        "vocabulary = set(tokens)\n",
        "print(len(vocabulary))\n",
        "frequency_dist = nltk.FreqDist(tokens)\n",
        "sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)[0:50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZgi-BzMFoEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove stop words form corpus\n",
        "tokens = [w for w in tokens if not w in stop_words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wyd6Oa9Fr1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split Dataset into Train and Test\n",
        "train_x = df.loc[:31, 'lyrics'].values\n",
        "Y_train = df.loc[:31, 'mood'].values\n",
        "test_x = df.loc[32:, 'lyrics'].values\n",
        "Y_test = df.loc[32:, 'mood'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMuTCY0rFufb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2bd6bb9-c624-463c-e857-a2a760a86aa7"
      },
      "source": [
        "#Feature Extraction using Tf-Idf\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_x)\n",
        "X_test = vectorizer.transform(test_x)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 231) (8, 231)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiMS4ijyFyGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "283107ce-9751-41c0-b07d-da26695e7281"
      },
      "source": [
        "#Naive Bayes Algorithm\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from  sklearn.metrics  import accuracy_score\n",
        "model = MultinomialNB().fit(X_train, Y_train)\n",
        "# Predict Output \n",
        "NBpred = model.predict(X_test)\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,model.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, NBpred))\n",
        "cm1=confusion_matrix(Y_test, NBpred)\n",
        "print(confusion_matrix(Y_test, NBpred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy ::  0.90625\n",
            "Test Accuracy  ::  0.625\n",
            "[[0 3]\n",
            " [0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxqiLAgHGMOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6fe711fc-f394-474e-d1a2-930f530e0fca"
      },
      "source": [
        "#Decision Tree Algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_train, Y_train)\n",
        "Y_pred = classifier.predict(X_test)\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,classifier.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, Y_pred))\n",
        "cm1=confusion_matrix(Y_test, Y_pred)\n",
        "print(confusion_matrix(Y_test, Y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy ::  1.0\n",
            "Test Accuracy  ::  0.625\n",
            "[[1 2]\n",
            " [1 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCNkgEtGU8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0263043c-40c7-4727-a2ec-c3721e925ef0"
      },
      "source": [
        "#SVM Algorithm\n",
        "from sklearn.svm import SVC,SVR\n",
        "svclassifier = SVC(kernel='linear')\n",
        "svclassifier.fit(X_train, Y_train)\n",
        "SVM_pred = svclassifier.predict(X_test)\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,svclassifier.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, SVM_pred))\n",
        "cm1=confusion_matrix(Y_test, SVM_pred)\n",
        "print(confusion_matrix(Y_test, SVM_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy ::  0.9375\n",
            "Test Accuracy  ::  0.625\n",
            "[[0 3]\n",
            " [0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tUwO9ovGfeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "72a3b152-6163-4c70-ab5b-1f2977098cc2"
      },
      "source": [
        "#Random Forest Algorithm\n",
        "clf = RandomForestClassifier(n_estimators=20, max_depth=5,random_state=42)\n",
        "model=clf.fit(X_train, Y_train)\n",
        "print(\"Trained model :: \",model)\n",
        "predictions =model.predict(X_test)\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,model.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, predictions))\n",
        "cm1=confusion_matrix(Y_test, predictions)\n",
        "print(confusion_matrix(Y_test, predictions))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained model ::  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)\n",
            "Train Accuracy ::  0.9375\n",
            "Test Accuracy  ::  0.625\n",
            "[[0 3]\n",
            " [0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT7MkNliG1qM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "37ca2145-c7f6-4a22-e5bf-226f5135634b"
      },
      "source": [
        "#Ada-Boost Algorithm\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "Model=clf.fit(X_train,Y_train)  \n",
        "print(\"Trained model :: \",Model)\n",
        "Ada_pred =Model.predict(X_test)\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,Model.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, Ada_pred))\n",
        "cm1=confusion_matrix(Y_test, Ada_pred)\n",
        "print(confusion_matrix(Y_test, Ada_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained model ::  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=100, random_state=0)\n",
            "Train Accuracy ::  1.0\n",
            "Test Accuracy  ::  0.5\n",
            "[[1 2]\n",
            " [2 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUEUSv-iG6wt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "1c2da84e-3481-4a19-9631-325bbe92b52e"
      },
      "source": [
        "#Balance Bagging Algorithm\n",
        ">>> from imblearn.ensemble import BalancedBaggingClassifier\n",
        ">>> bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
        "...                                 sampling_strategy='auto',\n",
        "...                                 replacement=False,\n",
        "...                                 random_state=0)\n",
        ">>> bbc.fit(X_train, Y_train)\n",
        "Bagpred = bbc.predict(X_test)\n",
        "\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,bbc.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, Bagpred))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm1=confusion_matrix(Y_test, Bagpred)\n",
        "print(confusion_matrix(Y_test, Bagpred))\n",
        "print(classification_report(Y_test, Y_pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy ::  0.9375\n",
            "Test Accuracy  ::  0.875\n",
            "[[2 1]\n",
            " [0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       আনন্দ       0.50      0.33      0.40         3\n",
            "       বেদনা       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.62         8\n",
            "   macro avg       0.58      0.57      0.56         8\n",
            "weighted avg       0.60      0.62      0.60         8\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvdBl0v0HIXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "10961fa9-f7b9-4081-d03f-9037d297fb05"
      },
      "source": [
        "#Bagging Algorithm\n",
        ">>> from sklearn.svm import SVC\n",
        ">>> from sklearn.ensemble import BaggingClassifier\n",
        ">>> from sklearn.datasets import make_classification\n",
        ">>> X, y = make_classification(n_samples=100, n_features=4,\n",
        "...                            n_informative=2, n_redundant=0,\n",
        "...                            random_state=0, shuffle=False)\n",
        ">>> Model = BaggingClassifier(base_estimator=SVC(),\n",
        "...                         n_estimators=10, random_state=0).fit(X_train, Y_train)\n",
        "\n",
        "print(\"Trained model :: \",Model)\n",
        "pred =Model.predict(X_test)\n",
        "print(\"Train Accuracy :: \", accuracy_score(Y_train,Model.predict(X_train)))\n",
        "print(\"Test Accuracy  :: \", accuracy_score(Y_test, pred))\n",
        "cm1=confusion_matrix(Y_test, pred)\n",
        "print(confusion_matrix(Y_test, pred))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained model ::  BaggingClassifier(base_estimator=SVC(C=1.0, cache_size=200, class_weight=None,\n",
            "                                     coef0=0.0, decision_function_shape='ovr',\n",
            "                                     degree=3, gamma='auto_deprecated',\n",
            "                                     kernel='rbf', max_iter=-1,\n",
            "                                     probability=False, random_state=None,\n",
            "                                     shrinking=True, tol=0.001, verbose=False),\n",
            "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
            "                  max_samples=1.0, n_estimators=10, n_jobs=None,\n",
            "                  oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
            "Train Accuracy ::  0.625\n",
            "Test Accuracy  ::  0.625\n",
            "[[0 3]\n",
            " [0 5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS-rss0CIiDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}